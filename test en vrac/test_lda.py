import os
import nltk
import gensim
from gensim import corpora
from gensim.models import LdaModel
from gensim.utils import simple_preprocess
from nltk.corpus import stopwords
from langchain.chains import LLMChain
from langchain.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq
from dotenv import load_dotenv


def preprocess(text, stop_words):
    """
    Tokenizes and preprocesses the input text, removing stopwords and short
    tokens.

    Parameters:
        text (str): The input text to preprocess.
        stop_words (set): A set of stopwords to be removed from the text.
    Returns:
        list: A list of preprocessed tokens.
    """
    result = []
    for token in simple_preprocess(text, deacc=True):
        if token not in stop_words and len(token) > 3:
            result.append(token)
    return result


def split_chunk(transcript):
    """
    Splits the transcript into chunks of text.

    Parameters:
        transcript (str): The transcript text to split.

    Returns:
        list: A list of text chunks.
    """
    
    lines = transcript.split("\n")
    chunks = []
    n = 20
    
    # Split the transcript into chunks n lines per chunk
    for i in range(0, len(lines), n):
        chunk = "\n".join(lines[i:min(i + n, len(lines))])
        chunks.append(chunk)
    
    return chunks


def get_topic_lists_from_pdf(transcript, num_topics, words_per_topic):
    """
    Extracts topics and their associated words from a video transcript using the
    Latent Dirichlet Allocation (LDA) algorithm.

    Parameters:
        transcript (str): The transcript text for topic extraction.
        num_topics (int): The number of topics to discover.
        words_per_topic (int): The number of words to include per topic.

    Returns:
        list: A list of num_topics sublists, each containing relevant words
        for a topic.
    """
    # Extract the text from each page into a list. Each page is considered a document
    documents = split_chunk(transcript)
    
    
    # Preprocess the documents
    nltk.download('stopwords')
    stop_words = set(stopwords.words(['english','french']))
    processed_documents = [preprocess(doc, stop_words) for doc in documents]

    # Create a dictionary and a corpus
    dictionary = corpora.Dictionary(processed_documents)
    corpus = [dictionary.doc2bow(doc) for doc in processed_documents]

    # Build the LDA model
    lda_model = LdaModel(
        corpus,
        num_topics=num_topics,
        id2word=dictionary,
        passes=15
        )

    # Retrieve the topics and their corresponding words
    topics = lda_model.print_topics(num_words=words_per_topic)

    # Store each list of words from each topic into a list
    topics_ls = []
    for topic in topics:
        words = topic[1].split("+")
        topic_words = [word.split("*")[1].replace('"', '').strip() for word in words]
        topics_ls.append(topic_words)

    return topics_ls


def topics_from_pdf(llm, transcript, num_topics, words_per_topic):
    """
    Generates descriptive prompts for LLM based on topic words extracted from a
    video transcript.

    This function takes the output of `get_topic_lists_from_pdf` function,
    which consists of a list of topic-related words for each topic, and
    generates an output string in bulleted nested list format.

    Parameters:
        llm (LLM): An instance of the Large Language Model (LLM) for generating
        responses.
        transcript (str): The text transcript for extracting topic-related words.
        num_topics (int): The number of topics to consider.
        words_per_topic (int): The number of words per topic to include.

    Returns:
        str: A response generated by the language model based on the provided
        topic words.
    """

    # Extract topics and convert them to string
    list_of_topicwords = get_topic_lists_from_pdf(transcript, num_topics,
                                                    words_per_topic)
    string_lda = ""
    for list in list_of_topicwords:
        string_lda += str(list) + "\n"

    print("-------------------")
    print(string_lda)
    print("-------------------")
    
    # Create the template
    template_string = '''Describe the topic of each of the {num_topics}
        double-quote delimited lists in a simple sentence and also write down
        three possible different subthemes. The lists are the result of an
        algorithm for topic discovery.
        Do not provide an introduction or a conclusion, only describe the
        topics. Do not mention the word "topic" when describing the topics.
        Use the following template for the response.

        1: <<<(sentence describing the topic)>>>
        - <<<(Phrase describing the first subtheme)>>>
        - <<<(Phrase describing the second subtheme)>>>
        - <<<(Phrase describing the third subtheme)>>>

        2: <<<(sentence describing the topic)>>>
        - <<<(Phrase describing the first subtheme)>>>
        - <<<(Phrase describing the second subtheme)>>>
        - <<<(Phrase describing the third subtheme)>>>

        ...

        n: <<<(sentence describing the topic)>>>
        - <<<(Phrase describing the first subtheme)>>>
        - <<<(Phrase describing the second subtheme)>>>
        - <<<(Phrase describing the third subtheme)>>>

        Lists: """{string_lda}""" '''

    # LLM call
    prompt_template = ChatPromptTemplate.from_template(template_string)
    chain = LLMChain(llm=llm, prompt=prompt_template)
    response = chain.run({
        "string_lda" : string_lda,
        "num_topics" : num_topics
        })

    return response



def get_transcript():
    with open("transcript.txt", "r", encoding="utf-8") as f:
        transcript = f.read()
    return transcript


load_dotenv()
groq_api_key = os.getenv("GROQ_API_KEY")
llm = ChatGroq(
            api_key=groq_api_key,
            model_name="llama3-8b-8192"
        )

num_topics = 5
words_per_topic = 30

summary = topics_from_pdf(llm, get_transcript(), num_topics, words_per_topic)
print(summary)